{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science â€“ Homework 7\n",
    "*COMP 5360 / MATH 4100, University of Utah, http://datasciencecourse.net/*\n",
    "\n",
    "Due: Friday, March 21, 2025 11:59pm.\n",
    "\n",
    "In this homework, you will use classification methods to classify handwritten digits (Part 1) and predict the satisfaction level of airline passengers (Part 2). We hope these exercises will give you an idea of the broad usage of classification methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Data\n",
    "First Name:\n",
    "<br>\n",
    "Last Name:\n",
    "<br>\n",
    "E-mail:\n",
    "<br>\n",
    "UID:\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and setup \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import tree, svm, metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: MNIST handwritten digits\n",
    "\n",
    "The MNIST handwritten digit dataset is a famous test dataset containing images of handwritten digits, together with labels indicating which digit is in each image. You will see that images are just matrices with scalar values, and that we can apply the classification algorithms we studied on them.\n",
    "\n",
    "Because both the features and the labels are present in this dataset (and labels for large datasets are generally difficult/expensive to obtain), this dataset is frequently used as a benchmark to compare various classification methods. For example, [this webpage](http://dia.fi.upm.es/~lbaumela/PracRF11/MNIST.html) gives a comparison of a variety of different classification methods on MNIST (Note that the tests on this website are for higher resolution images than we'll use.) \n",
    "\n",
    "In this problem, we'll use scikit-learn to compare classification methods on the MNIST dataset. \n",
    "\n",
    "There are several versions of the MNIST dataset. We'll use the one that is built-into scikit-learn, described [here](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html). \n",
    "\n",
    "1) Classes: 10 (one for each digit)\n",
    "2) Samples total: 1797\n",
    "3) Samples per class: $\\approx$180\n",
    "4) Dimensionality: 64 (8 pixels by 8 pixels)\n",
    "5) Features: integers 0-16 (grayscale value; 0 is white, 16 is black)\n",
    "\n",
    "Here are some examples of the images. Note that the digits have been size-normalized and centered in a fixed-size ($8\\times8$ pixels) image.\n",
    "\n",
    "<img src=\"http://scikit-learn.org/stable/_images/sphx_glr_plot_digits_classification_001.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we will scale the data before running them through our algorithms. You can read details about scaling and why it's important [here](http://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "n_digits: 10, n_samples 1797, n_features 64\n"
     ]
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "#X = digits.data\n",
    "X = scale(digits.data)\n",
    "y = digits.target\n",
    "print(type(X))\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "n_digits = len(np.unique(digits.target))\n",
    "print(\"n_digits: %d, n_samples %d, n_features %d\" % (n_digits, n_samples, n_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===\n",
      "The digit\n",
      "0\n",
      "===\n",
      "The raw data\n",
      "[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
      " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
      " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
      " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
      " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
      " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
      " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
      " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n",
      "===\n",
      "The scaled data\n",
      "[ 0.         -0.33501649 -0.04308102  0.27407152 -0.66447751 -0.84412939\n",
      " -0.40972392 -0.12502292 -0.05907756 -0.62400926  0.4829745   0.75962245\n",
      " -0.05842586  1.12772113  0.87958306 -0.13043338 -0.04462507  0.11144272\n",
      "  0.89588044 -0.86066632 -1.14964846  0.51547187  1.90596347 -0.11422184\n",
      " -0.03337973  0.48648928  0.46988512 -1.49990136 -1.61406277  0.07639777\n",
      "  1.54181413 -0.04723238  0.          0.76465553  0.05263019 -1.44763006\n",
      " -1.73666443  0.04361588  1.43955804  0.         -0.06134367  0.8105536\n",
      "  0.63011714 -1.12245711 -1.06623158  0.66096475  0.81845076 -0.08874162\n",
      " -0.03543326  0.74211893  1.15065212 -0.86867056  0.11012973  0.53761116\n",
      " -0.75743581 -0.20978513 -0.02359646 -0.29908135  0.08671869  0.20829258\n",
      " -0.36677122 -1.14664746 -0.5056698  -0.19600752]\n"
     ]
    }
   ],
   "source": [
    "# this is what one digit (a zero) looks like\n",
    "\n",
    "print(\"===\\nThe digit\")\n",
    "print(digits.target[0])\n",
    "\n",
    "print(\"===\\nThe raw data\")\n",
    "print(digits.images[0])\n",
    "\n",
    "print(\"===\\nThe scaled data\")\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot a few of the images\n",
    "\n",
    "plt.figure(figsize= (10, 10))    \n",
    "for ii in np.arange(25):\n",
    "    plt.subplot(5, 5, ii+1)\n",
    "    plt.imshow(np.reshape(digits.images[ii,:],(8,8)), cmap='Greys',interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might find [this webpage](https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html#sphx-glr-auto-examples-classification-plot-digits-classification-py) to be generally helpful for this exercise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1: Classification with Support Vector Machines (SVM)\n",
    "\n",
    "1. Split the data into a training and test set using the command \n",
    "```\n",
    "train_test_split(X, y, random_state=1, test_size=0.8)\n",
    "```\n",
    "    1. Use SVM with an `rbf` kernel and parameter `C=100` to build a classifier using the *training dataset*.\n",
    "    2. Using the *test dataset*, evaluate the accuracy of the model. Again using the *test dataset*, compute the confusion matrix. What is the most common mistake that the classifier makes? **Note: this corresponds to the largest off-diagonal entry of the confusion matrix.**\n",
    "    3. Print all of these misclassified digits as images. \n",
    "    4. Using the 'cross_val_score' function, evaluate the accuracy of the SVM for 100 different values of the parameter C between 1 and 400. What is the best value? \n",
    "    5. Try to train and test the algorithm on the raw (non-scaled) data. Report the accuracy score and confusion matrix for different settings of `gamma`. You may use whatever C value you determined worked well on the scaled data in \"part 4\". What is your observation of the results on the raw data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Interpretation**: TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2: Prediction with k-nearest neighbors\n",
    "`Repeat` task 1.1 using k-nearest neighbors (k-NN). In part 2, use k=10. In part 5, find the best value of k. \n",
    "\n",
    "Work on every single question except the last one (You don't need to handle the non-scaled data here) in task 1.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Interpretation**: TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Satisfaction of Airline Passengers\n",
    "\n",
    "For this problem, you will use classification tools to predict the satisfaction of airline passengers based on attributes such as the seat comfort, inflight wifi service, ease of online booking, leg-room service, check-in service, and some variables related to the content of the dataset. You can learn details about the dataset in the [info.txt](./Satisfaction/info.txt). \n",
    "\n",
    "The dataset contains variables describing 103904 airline passengers.\n",
    "There are 25 variables associated with each passenger. Of these, 23 are *predictor* variables and 1 variable (id) will not be used. The 'satisfaction' column is what we will use to define the satisfaction level of the passengers, which is what we will try to predict. You should read about the predictor variables in the file *info.txt*.\n",
    "\n",
    "### Task 2.1 Import and preprocessing the data \n",
    "* Use the pandas.read_csv() function to import the dataset. Then, **print** shape of the data and first few lines of data.\n",
    "* Convert the ordinal data columns (e.g. 'Gender', 'Customer Type', 'Type of Travel', 'Class', 'satisfaction') to numerical data. \n",
    "* Drop all rows with NaN values in any column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2 Predictor and Predicted variable\n",
    "* To use [scikit-learn](http://scikit-learn.org), we'll need to save the data as a numpy array. Use the *DataFrame.values* command to export the predictor variables as a numpy array called *X* this array should not include our target variable (satisfacton). We don't need the id, so let's drop the column. \n",
    "* Export the 'satisfaction' column as a separate numpy array, called *satisfaction*. Create a binary numpy array, *y*, which indicates whether the airline passenger was satisfied or not.\n",
    "* Print *y* array\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.3 Classification using k-NN\n",
    "\n",
    "Develop a k-NN classification model for the data. Use cross validation to choose the best value of k. What is the best accuracy you can obtain on the test data? \n",
    "Plot graph of accuracy with various values of k to show your result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.4 Classification using SVM\n",
    "\n",
    "Develop a support vector machine classification model for the data. Show the results of cross-validation along with best parameter at the end.\n",
    "\n",
    "\n",
    "*Hint:* SVM is more computationally expensive, so you might want to start by using only a fraction of the data, say 4,000 articles. It takes multiple minutes to run on the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.5 Classification using decision trees\n",
    "\n",
    "Develop a decision tree classification model for the data. Use cross validation to choose good values of the max tree depth (*max_depth*) and minimum samples split (*min_samples_split*). \n",
    "Show the results of cross-validation along with best parameter at the end.\n",
    "We don't need a plot here, we only need cross validation output and the optimal setting of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.6 Describe your findings\n",
    "1. Which method (k-NN, SVM, Decision Tree) worked best?\n",
    "    1. How did different parameters influence the accuracy?\n",
    "    2. Which model is easiest to interpret?\n",
    "    3. How would you interpret your results?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Solution:** TODO"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
